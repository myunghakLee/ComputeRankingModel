{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T06:50:47.219743Z",
     "start_time": "2021-02-04T06:50:47.194562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4860, 0.1038, 0.0934], requires_grad=True) tensor([-0.5144,  1.2280,  0.5854], requires_grad=True)\n",
      "tensor([-1., -1.,  1.])\n",
      "tensor(13.1227, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "loss = nn.MarginRankingLoss(margin = 13.0)\n",
    "input1 = torch.randn(3, requires_grad=True)\n",
    "input2 = torch.randn(3, requires_grad=True)\n",
    "target = torch.randn(3).sign()\n",
    "output = loss(input1, input2, target)\n",
    "print(input1, input2)\n",
    "print(target)\n",
    "print(output)\n",
    "\n",
    "output.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T06:50:47.659144Z",
     "start_time": "2021-02-04T06:50:47.647008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.0004, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(-target * (input1-input2)) + 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T06:50:48.013753Z",
     "start_time": "2021-02-04T06:50:47.997795Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_nums = 10000):\n",
    "        self.dataset = []\n",
    "        for i in range(data_nums):\n",
    "            data = {}\n",
    "            data[\"input\"] = torch.randn(1,10)\n",
    "#             data[\"output\"] = torch.tensor([[sum(data[\"input\"][0][max(0, i-1):min(i+2, 11)]) for i in range(len(data[\"input\"][0]))]])\n",
    "            data[\"output\"] = torch.argsort(data[\"input\"]).float()\n",
    "#             data[\"output\"] = torch.randn(1,10) + 10\n",
    "            self.dataset.append(data)\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T06:50:49.020353Z",
     "start_time": "2021-02-04T06:50:49.005718Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_length = 10, output_length = 10):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "            nn.Conv1d(1,1,kernel_size=3,padding=1),\n",
    "        )\n",
    "#         self.Conv2d = nn.Conv2d(1,1,kernel_size=3,padding=1)\n",
    "    def forward(self, data):\n",
    "        out = self.seq(data)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T15:28:37.368374Z",
     "start_time": "2021-02-04T15:28:37.357874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7625597484987"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3**27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T06:50:50.086034Z",
     "start_time": "2021-02-04T06:50:49.822549Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TestDataset()\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T06:51:02.551324Z",
     "start_time": "2021-02-04T06:50:57.157017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (seq): Sequential(\n",
       "    (0): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (2): Tanh()\n",
       "    (3): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (5): Tanh()\n",
       "    (6): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (7): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (8): Tanh()\n",
       "    (9): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (10): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (11): Tanh()\n",
       "    (12): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (13): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "MSE = nn.MSELoss()\n",
    "CS = nn.CosineSimilarity(dim = 2)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size = 4096, shuffle = True)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T06:51:55.827955Z",
     "start_time": "2021-02-04T06:51:55.693711Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9c8d1d43570c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#         print(torch.sum(loss))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "before_param_data = {}\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        before_param_data[name] = copy.deepcopy(param.data)\n",
    "        \n",
    "for epoch in range(1000000):\n",
    "    loss_mean = []\n",
    "    for i, batch in (enumerate(data_loader)):\n",
    "        input_data, GT = (batch[\"input\"].to(device), batch[\"output\"].to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictTE = model(input_data)\n",
    "        sort_idx = torch.argsort(predictTE, dim = 2).float()\n",
    "#         predictTE = predictTE * 0 + sort_idx\n",
    "\n",
    "\n",
    "        loss = MSE(sort_idx, GT)\n",
    "#         loss = loss + torch.mean(1. - (CS(predictTE, GT))) * 5\n",
    "#         print(input_data.shape)\n",
    "#         print(GT.shape)\n",
    "#         assert False, \"AA\"\n",
    "#         print(GT[0])\n",
    "#         print(loss.shape)\n",
    "#         print(torch.sum(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_mean.append(loss.cpu().item())\n",
    "    if epoch % 20 == 19:\n",
    "        print(np.mean(loss_mean))\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "#                 print(name, param.data)\n",
    "#                 print(name, before_param_data[name])\n",
    "#                 print(predictTE[0])\n",
    "#                 print(GT[0])\n",
    "\n",
    "#                 print((before_param_data[name] == param.data).any())\n",
    "#                 assert (before_param_data[name] != param.data).any(), \"BACK PROPAGATION FAIL!!!!!!!!!!!!!!!!!\"\n",
    "#                 break\n",
    "                pass\n",
    "        print(predictTE[0])\n",
    "        print(torch.argsort(predictTE[0]).float())\n",
    "        print(GT[0])\n",
    "#         print(loss.requires_grad)\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-04T04:40:42.708Z"
    }
   },
   "outputs": [],
   "source": [
    "model.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-04T04:40:42.708Z"
    }
   },
   "outputs": [],
   "source": [
    "input1 = torch.randn(100, 128)\n",
    "input2 = torch.randn(100, 128)\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(input1, input2)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-04T04:40:42.709Z"
    }
   },
   "outputs": [],
   "source": [
    "(before_param_data[name] == param.data).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-04T04:40:42.709Z"
    }
   },
   "outputs": [],
   "source": [
    "param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-04T04:40:42.710Z"
    }
   },
   "outputs": [],
   "source": [
    "assert False, \"AA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-04T04:40:42.710Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
